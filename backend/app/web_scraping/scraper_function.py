import json
from pathlib import Path
from urllib.parse import urlparse
from app.web_scraping.web_scraper import WebsiteProcessor

 
def web_scraping(url):
    # Website to scrape
    WEBSITE_URL = url

    print("="*60)
    print("RAG DATA PREPARATION PIPELINE")
    print("="*60)

    print("\nğŸ“¦ Initializing processor...")
    processor = WebsiteProcessor(WEBSITE_URL)

    print("\nğŸŒ Scraping website...")
    documents = processor.scrape_website()
    print(f"   âœ… Scraped {len(documents)} pages")

    print("\nğŸ§¹ Cleaning documents...")
    cleaned_docs = processor.clean_documents()
    print(f"   âœ… Cleaned {len(cleaned_docs)} documents")

    print("\nğŸ“„ Creating chunks...")
    chunks = processor.create_chunks(chunk_size=1000, chunk_overlap=200)
    print(f"   âœ… Created {len(chunks)} chunks")

    print("\n" + "="*60)
    print("PROCESSING COMPLETE!")
    print("="*60)

    embedding_path = processor.website_folder / "chunks" / "embedding_ready.json"
    if embedding_path.exists():
        with open(embedding_path, 'r', encoding='utf-8') as f:
            embedding_data = json.load(f)
        print(f"\nğŸ“Š Statistics:")
        print(f"   â€¢ Total chunks ready for embedding: {embedding_data['total_chunks']}")
        print(f"   â€¢ Average chunk size: ~1000 characters")
        print(f"   â€¢ Ready for vector database: YES âœ…")
    else:
        print("Embedding data not found.")